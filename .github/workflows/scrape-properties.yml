name: Scrape Properties

on:
  schedule:
    # Run every 6 hours (UTC timezone)
    # Format: minute hour day month day-of-week
    # This runs at: 00:00, 06:00, 12:00, 18:00 UTC
    - cron: '0 */6 * * *'
  workflow_dispatch: # Allows manual trigger from GitHub Actions UI

jobs:
  scrape:
    runs-on: ubuntu-latest
    name: Trigger Property Scraping
    steps:
      - name: Trigger Supabase Edge Function
        run: |
          echo "Triggering property scraping..."
          
          RESPONSE=$(curl -s -w "\nHTTP_CODE:%{http_code}" -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}" \
            -d '{"source":"all","city":"cape-town"}' \
            "${{ secrets.SUPABASE_URL }}/functions/v1/scrape-properties")
          
          HTTP_CODE=$(echo "$RESPONSE" | grep -o "HTTP_CODE:[0-9]*" | cut -d: -f2)
          BODY=$(echo "$RESPONSE" | sed '/HTTP_CODE:/d')
          
          echo "Response HTTP Code: $HTTP_CODE"
          echo "Response Body:"
          echo "$BODY" | jq '.' || echo "$BODY"
          
          if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ]; then
            echo "✅ Scraping job triggered successfully!"
            exit 0
          else
            echo "❌ Failed to trigger scraping job (HTTP $HTTP_CODE)"
            exit 1
          fi

